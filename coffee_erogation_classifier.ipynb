{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coffe Classifier: Thesis project for Bythem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ALESSANDRO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "from preprocessing import dataset_preprocessing, mixup, tensorflow_to_numpy_dataset\n",
    "from custom_mobilenet_v2 import MobileNet_v2\n",
    "from plotting import plot_training_history, plotting_confusion_matrix\n",
    "from utils import get_zipped_model_size, print_model_weights_sparsity\n",
    "from evaluation import evaluate_lite_model\n",
    "from distiller import Distiller, WarmUpCosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../dataset_04\"\n",
    "\n",
    "MODEL_NAME = \"\"\n",
    "DISTILLED_MODEL_NAME = \"\"\n",
    "PRUNED_MODEL_NAME = \"\"\n",
    "QUANTIZED_MODEL_NAME = \"\"\n",
    "\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 224\n",
    "INPUT_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "SCALE = 127.5\n",
    "OFFSET = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1281 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.utils.image_dataset_from_directory(DATASET_PATH,\n",
    "                                                   shuffle = True,\n",
    "                                                   batch_size = BATCH_SIZE,\n",
    "                                                   image_size = (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "class_names = dataset.class_names\n",
    "number_classes = len(class_names)\n",
    "\n",
    "training_dataset, validation_dataset, testing_dataset = dataset_preprocessing(dataset,\n",
    "                                                                              train_size=0.80,\n",
    "                                                                              validation_size=0.1, \n",
    "                                                                              augmentation_flag = True, \n",
    "                                                                              rescaling_flag = True, \n",
    "                                                                              prefetch_flag = True, \n",
    "                                                                              scale = SCALE, \n",
    "                                                                              offset = OFFSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cioccolata',\n",
       "  'cioccolata senza paletta',\n",
       "  'errore',\n",
       "  'espresso',\n",
       "  'espresso senza paletta',\n",
       "  'macchiato',\n",
       "  'macchiato senza paletta',\n",
       "  'the',\n",
       "  'the senza paletta'],\n",
       " 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names, number_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 1024\n",
      "Number of validation images: 128\n",
      "Number of testing images: 192\n"
     ]
    }
   ],
   "source": [
    "print('Number of training images:', len(training_dataset)*BATCH_SIZE)\n",
    "print('Number of validation images:', len(validation_dataset)*BATCH_SIZE)\n",
    "print('Number of testing images:', len(testing_dataset)*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up steps:  320000\n",
      "Warm-up steps:  240000.0\n"
     ]
    }
   ],
   "source": [
    "example_epochs = 5000\n",
    "dataset_num_train_examples = len(training_dataset)*BATCH_SIZE\n",
    "steps_per_epoch = dataset_num_train_examples // BATCH_SIZE\n",
    "total_steps = steps_per_epoch * example_epochs\n",
    "warm_up_steps = 0.75*total_steps\n",
    "\n",
    "print(\"Warm-up steps: \", total_steps )\n",
    "print(\"Warm-up steps: \", warm_up_steps )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transfer learning model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.2\n",
    "FREEZING_PERCENTAGE = 1\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = keras.applications.MobileNetV2(input_shape = INPUT_SHAPE, \n",
    "                                                   include_top=False, \n",
    "                                                   weights='imagenet',\n",
    "                                                   alpha=0.35,\n",
    "                                                   classes=number_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set weights from pre_trained model and freeze a % of the pre-trained model for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet_v2(input_shape=INPUT_SHAPE, alpha=0.35, num_classes=number_classes, dropout=DROPOUT)\n",
    "\n",
    "count = 0\n",
    "for i, layer in enumerate(pre_trained_model.layers):\n",
    "        model.layers[i].set_weights(layer.get_weights())\n",
    "        count = count +1 \n",
    "\n",
    "for i in range(int(count*FREEZING_PERCENTAGE)):\n",
    "    model.layers[i].trainable= False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num_train_examples = len(training_dataset)*BATCH_SIZE\n",
    "steps_per_epoch = dataset_num_train_examples // BATCH_SIZE\n",
    "total_steps = steps_per_epoch * EPOCHS\n",
    "\n",
    "learning_rate_fn = keras.optimizers.schedules.PolynomialDecay(\n",
    "    5e-3,\n",
    "    total_steps,\n",
    "    1e-3,\n",
    "    power=3)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lrs = learning_rate_fn(np.arange(0,total_steps))\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Step\", fontsize=14)\n",
    "plt.ylabel(\"LR\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate=learning_rate_fn),\n",
    "              loss= keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True)\n",
    "\n",
    "history = model.fit(training_dataset,\n",
    "                    validation_data=validation_dataset,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, baseline_accuracy = model.evaluate(testing_dataset, verbose = 0)\n",
    "print('Accuracy: ', round(baseline_accuracy*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_confusion_matrix(testing_dataset, model, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    model.save('saved_models/' + MODEL_NAME + '.keras')\n",
    "    print(\"Salvato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Knowladge distillation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WARMUP_STEPS = 80000\n",
    "INIT_LR = 0.003\n",
    "DISTILLATION_EPOCHS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = keras.models.load_model('saved_models/' + MODEL_NAME + '.keras')\n",
    "\n",
    "teacher_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "student_model = MobileNet_v2(input_shape=INPUT_SHAPE, alpha=0.35, num_classes=number_classes, dropout=DROPOUT, minimization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = WarmUpCosine(\n",
    "    learning_rate_base=INIT_LR,\n",
    "    total_steps=total_steps,\n",
    "    warmup_learning_rate=0.0,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    ")\n",
    "\n",
    "lrs = lr_schedule(np.arange(0,total_steps))\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Step\", fontsize=14)\n",
    "plt.ylabel(\"LR\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_training_dataset = training_dataset.map(mixup, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller = Distiller(student=student_model, teacher= teacher_model, alpha=0.1, temperature=10)\n",
    "\n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss = keras.losses.KLDivergence()\n",
    ")\n",
    "\n",
    "history = distiller.fit(mixup_training_dataset, epochs= DISTILLATION_EPOCHS, validation_data= validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = history.history['sparse_categorical_accuracy']\n",
    "validation_accuracy = history.history['val_sparse_categorical_accuracy']\n",
    "training_loss = history.history['student_loss']\n",
    "validation_loss = history.history['val_student_loss']\n",
    "\n",
    "epochs_range = range(len(training_accuracy))\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, training_accuracy,   label = 'Trainin Accuracy')\n",
    "plt.plot(epochs_range, validation_accuracy, label = 'Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy for training and validation')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range, training_loss,   label = 'Trainin Loss')\n",
    "plt.plot(epochs_range, validation_loss, label = 'Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss for training and validation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "_, teacher_accuracy = teacher_model.evaluate(testing_dataset, verbose = 0)\n",
    "_, student_accuracy = student_model.evaluate(testing_dataset, verbose = 0)\n",
    "print('Teacher model accuracy: ', round(teacher_accuracy*100, 3), '%')\n",
    "print('Student model accuracy: ', round(student_accuracy*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    student_model.save('saved_models/' + DISTILLED_MODEL_NAME + '.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pruned Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRUNING_EPOCHS = 3\n",
    "INITIAL_SPARSITY = 0.20\n",
    "FINAL_SPARSITY = 0.60\n",
    "FREQUENCY = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('saved_models/' + MODEL_NAME + '.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_mobilenet_v2 import MobileNet_v2\n",
    "\n",
    "custom_model = MobileNet_v2(INPUT_SHAPE, 0.35, number_classes, dropout=DROPOUT)\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "        custom_model.layers[i].set_weights(layer.get_weights())\n",
    "\n",
    "custom_model.compile(optimizer = keras.optimizers.Adam(1e-3),\n",
    "              loss= keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.trainable= True\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "num_images = (len(training_dataset)) *BATCH_SIZE\n",
    "end_step = np.ceil(num_images / BATCH_SIZE).astype(np.int32) * PRUNING_EPOCHS\n",
    "\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=INITIAL_SPARSITY, \n",
    "                                                             final_sparsity=FINAL_SPARSITY,\n",
    "                                                             begin_step=0, \n",
    "                                                             end_step=end_step,\n",
    "                                                             frequency = FREQUENCY)}\n",
    "\n",
    "\n",
    "pruned_model = prune_low_magnitude(custom_model, **pruning_params)\n",
    "\n",
    "callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "\n",
    "pruned_model.compile(optimizer= keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                     loss= keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fine tune the model\n",
    "pruned_model.fit(training_dataset,\n",
    "                 validation_data=validation_dataset,\n",
    "                 epochs= PRUNING_EPOCHS,\n",
    "                 verbose=1,\n",
    "                 callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model.compile(optimizer = keras.optimizers.Adam(1e-3),\n",
    "              loss= keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True )\n",
    "\n",
    "pruned_model.fit(training_dataset,\n",
    "                 validation_data=validation_dataset,\n",
    "                 epochs=EPOCHS,\n",
    "                 callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pruned_accuracy = pruned_model.evaluate(testing_dataset, verbose = 0)\n",
    "print('Pruned accuracy: '   , round(100* pruned_accuracy,3) ,   '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "if SAVE:\n",
    "    stripped_pruned_model.save('saved_models/' + PRUNED_MODEL_NAME + '.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original model size: \", get_zipped_model_size('saved_models/' + MODEL_NAME + '.keras')/10**6, ' MB')\n",
    "print(\"Original model size: \", get_zipped_model_size('saved_models/' + PRUNED_MODEL_NAME + '.keras')/10**6, ' MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Quantized model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('saved_models/' + PRUNED_MODEL_NAME + '.keras')\n",
    "\n",
    "model.compile(optimizer = keras.optimizers.Adam(1e-3),\n",
    "              loss= keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_batch_np, labels_batch_np = tensorflow_to_numpy_dataset(testing_dataset)\n",
    "\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(images_batch_np).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model);\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "model_integer_quantization = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_lite_models/' + QUANTIZED_MODEL_NAME + '.tflite', \"wb\") as f:\n",
    "    f.write(model_integer_quantization)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='saved_lite_models/' + MODEL_NAME + '.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "quantized_accuracy = evaluate_lite_model(interpreter, testing_dataset, class_names=class_names, show_confusion_matrix=True)\n",
    "print(\"Accuracy of compressed model model: %.2f\" %(quantized_accuracy*100) , '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original model size: \", get_zipped_model_size('saved_models/' + PRUNED_MODEL_NAME + '.keras')/10**6, ' MB')\n",
    "print(\"Quantized model size: \", get_zipped_model_size('saved_lite_models/' + QUANTIZED_MODEL_NAME + '.tflite')/10**3, ' kB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check for size and compression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original model size: \", get_zipped_model_size('saved_models/' + MODEL_NAME + '.keras')/10**6, ' MB')\n",
    "print(\"Original model size: \", get_zipped_model_size('saved_models/' + PRUNED_MODEL_NAME + '.keras')/10**6, ' MB')\n",
    "print(\"Quantized model size: \", get_zipped_model_size('saved_lite_models/' + QUANTIZED_MODEL_NAME + '.tflite')/10**3, ' kB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test compressed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: '          ,round(baseline_accuracy*100, 3), '%')\n",
    "print('Pruned accuracy: '   ,round(100* pruned_accuracy,3) ,   '%')\n",
    "print(\"Accuracy of compressed model model: %.2f\" %(quantized_accuracy*100) , '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
